
# **Company Similarity Retrieval Service**

## **Overview**
This project implements a Python-based service to retrieve and rank companies similar to a given target company. The similarity is determined using textual embeddings stored in PostgreSQL with the pgvector extension. The service uses machine learning techniques, specifically embeddings generated by Sentence-BERT, to measure similarity and provides results via a RESTful API.

---

## **Features**
1. **Data Preprocessing**:
   - Merge multiple CSV files (`companies.csv`, `company_industries.csv`, `company_specialities.csv`) into a unified dataset.
   - Clean and normalize textual data.
2. **Embedding Generation**:
   - Use a pre-trained Sentence-BERT model to generate embeddings for company descriptions.
   - Store embeddings in PostgreSQL with pgvector extension.
3. **Similarity Computation**:
   - Perform similarity search directly in PostgreSQL using the `&lt;=&gt;` operator for cosine similarity.
4. **API Development**:
   - Expose an API endpoint `/retrieve_similar_companies/{company_id}` to return the top similar companies.
5. **Progress Tracking**:
   - Log progress during data loading and embedding generation.

---

## **Technologies Used**
- **Programming Language**: Python
- **Libraries**:
  - `fastapi`: API development
  - `sqlalchemy`: Database interaction
  - `sentence-transformers`: Embedding generation
  - `psycopg2-binary`: PostgreSQL driver
  - `tqdm`: Progress tracking
- **Database**: PostgreSQL with pgvector extension
- **Containerization**: Docker

---

## **Setup Instructions**

### **1. Clone the Repository**
```

git clone <repository-url>
cd project

```

### **2. Install Dependencies**
Create a virtual environment and install required Python packages:
```

python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt

```

### **3. Start Services**
Run the following command to start PostgreSQL and the FastAPI application:
```

docker-compose up --build

```

### **4. Load Data into PostgreSQL**
Run the script to load data and generate embeddings:
```

python load_data_to_postgres.py

```

### **5. Access the API**
Use tools like Postman or CURL to interact with the API:
- Endpoint: `/retrieve_similar_companies/{company_id}`
- Example Request:
```

curl http://localhost:8000/retrieve_similar_companies/1415

```
- Example Response:
```

{
"company_id": 1415,
"similar_companies": [
{"id": 1016, "similarity": 0.89},
{"id": 1023, "similarity": 0.87},
{"id": 1032, "similarity": 0.85}
]
}

```

---

## **Directory Structure**
```

project/
├── app/
│   ├── main.py          \# FastAPI implementation
│   ├── database.py      \# Database connection setup (PostgreSQL)
│   └── __init__.py
├── data/
│   ├── companies.csv    \# Company data
│   ├── company_industries.csv \# Industry mapping
│   ├── company_specialities.csv \# Specialities mapping
├── load_data_to_postgres.py \# Script for loading data into PostgreSQL
├── requirements.txt     \# Python dependencies
├── Dockerfile           \# Docker configuration for FastAPI app
├── docker-compose.yml   \# Docker Compose setup for services (PostgreSQL + FastAPI)
└── README.md            \# Project documentation (this file)

```

---

## **API Documentation**

### Endpoint: `/retrieve_similar_companies/{company_id}`
#### Request:
- Method: `GET`
- URL Parameter: `company_id` (integer)

#### Response:
```

{
"company_id": <target_company_id>,
"similar_companies": [
{
"id": <similar_company_id>,
"similarity": <similarity_score>
},
...
]
}

```

---

## **Testing Instructions**
Run unit tests using Pytest:
```

pytest tests/

```

---

## **Performance Optimization**

1. Add vector index for faster similarity search:
```

CREATE INDEX ON companies USING hnsw (embedding vector_cosine_ops);

```
2. Use connection pooling for production deployments.

---

## **Future Improvements**
1. Add filtering capabilities (e.g., filter by industry or location).
2. Implement caching for frequently queried companies.
3. Scale PostgreSQL horizontally using partitioning or sharding.

